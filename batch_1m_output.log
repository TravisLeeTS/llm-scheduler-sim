Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 1 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
======================================================================
BATCH 1M CONFIGURATION RUNNER
======================================================================

Missing configurations: 43
Estimated time: 64 - 86 minutes


[1/43] Running: GPUs=1, K=32
--------------------------------------------------
Traceback (most recent call last):
  File "C:\Users\tings\llm_scheduler_sim\scripts\batch_1m_configs.py", line 224, in <module>
    main()
  File "C:\Users\tings\llm_scheduler_sim\scripts\batch_1m_configs.py", line 211, in main
    print(f"\u2717 FAILED: {error[:100] if error else 'Unknown error'}")
  File "C:\Users\tings\AppData\Local\Programs\Python\Python312\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2717' in position 0: character maps to <undefined>
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 2 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 2 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 2 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 4 GPUs, K=1...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [0, 10000) tokens, B_MAX=9
[Scheduler Init] multi_bin_dynamic: K_BINS=1 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 4 GPUs, K=2...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 80) tokens, B_MAX=128
  Bin 1: [80, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=2 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 4 GPUs, K=4...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 42) tokens, B_MAX=128
  Bin 1: [42, 80) tokens, B_MAX=128
  Bin 2: [80, 167) tokens, B_MAX=128
  Bin 3: [167, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=4 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 4 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 4 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 4 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 8 GPUs, K=1...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [0, 10000) tokens, B_MAX=9
[Scheduler Init] multi_bin_dynamic: K_BINS=1 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 8 GPUs, K=2...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 80) tokens, B_MAX=128
  Bin 1: [80, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=2 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 8 GPUs, K=4...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 42) tokens, B_MAX=128
  Bin 1: [42, 80) tokens, B_MAX=128
  Bin 2: [80, 167) tokens, B_MAX=128
  Bin 3: [167, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=4 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 8 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 8 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 8 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 16 GPUs, K=1...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [0, 10000) tokens, B_MAX=9
[Scheduler Init] multi_bin_dynamic: K_BINS=1 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 16 GPUs, K=2...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 80) tokens, B_MAX=128
  Bin 1: [80, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=2 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 16 GPUs, K=4...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 42) tokens, B_MAX=128
  Bin 1: [42, 80) tokens, B_MAX=128
  Bin 2: [80, 167) tokens, B_MAX=128
  Bin 3: [167, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=4 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 16 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 16 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 16 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 32 GPUs, K=1...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [0, 10000) tokens, B_MAX=9
[Scheduler Init] multi_bin_dynamic: K_BINS=1 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 32 GPUs, K=2...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 80) tokens, B_MAX=128
  Bin 1: [80, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=2 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 32 GPUs, K=4...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 42) tokens, B_MAX=128
  Bin 1: [42, 80) tokens, B_MAX=128
  Bin 2: [80, 167) tokens, B_MAX=128
  Bin 3: [167, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=4 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 32 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 32 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 32 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 64 GPUs, K=1...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [0, 10000) tokens, B_MAX=9
[Scheduler Init] multi_bin_dynamic: K_BINS=1 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 64 GPUs, K=2...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 80) tokens, B_MAX=128
  Bin 1: [80, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=2 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 64 GPUs, K=4...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 42) tokens, B_MAX=128
  Bin 1: [42, 80) tokens, B_MAX=128
  Bin 2: [80, 167) tokens, B_MAX=128
  Bin 3: [167, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=4 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 64 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 64 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 64 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 100 GPUs, K=1...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [0, 10000) tokens, B_MAX=9
[Scheduler Init] multi_bin_dynamic: K_BINS=1 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 100 GPUs, K=2...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 80) tokens, B_MAX=128
  Bin 1: [80, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=2 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 100 GPUs, K=4...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 42) tokens, B_MAX=128
  Bin 1: [42, 80) tokens, B_MAX=128
  Bin 2: [80, 167) tokens, B_MAX=128
  Bin 3: [167, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=4 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 100 GPUs, K=8...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 30) tokens, B_MAX=128
  Bin 1: [30, 42) tokens, B_MAX=128
  Bin 2: [42, 56) tokens, B_MAX=128
  Bin 3: [56, 80) tokens, B_MAX=128
  Bin 4: [80, 117) tokens, B_MAX=128
  Bin 5: [117, 167) tokens, B_MAX=128
  Bin 6: [167, 281) tokens, B_MAX=83
  Bin 7: [281, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=8 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 100 GPUs, K=16...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 25) tokens, B_MAX=128
  Bin 1: [25, 30) tokens, B_MAX=128
  Bin 2: [30, 37) tokens, B_MAX=128
  Bin 3: [37, 42) tokens, B_MAX=128
  Bin 4: [42, 48) tokens, B_MAX=128
  Bin 5: [48, 56) tokens, B_MAX=128
  Bin 6: [56, 67) tokens, B_MAX=128
  Bin 7: [67, 80) tokens, B_MAX=128
  Bin 8: [80, 98) tokens, B_MAX=128
  Bin 9: [98, 117) tokens, B_MAX=128
  Bin 10: [117, 143) tokens, B_MAX=128
  Bin 11: [143, 167) tokens, B_MAX=120
  Bin 12: [167, 200) tokens, B_MAX=102
  Bin 13: [200, 281) tokens, B_MAX=77
  Bin 14: [281, 363) tokens, B_MAX=57
  Bin 15: [363, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=16 + DynamicBatcher (SLA controller)
Loading 1000000 requests...
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 1000000 requests from dataset
SLA thresholds: Per-token=30.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Running simulation with 100 GPUs, K=32...
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 1000000 requests:
  Bin 0: [1, 21) tokens, B_MAX=128
  Bin 1: [21, 25) tokens, B_MAX=128
  Bin 2: [25, 28) tokens, B_MAX=128
  Bin 3: [28, 30) tokens, B_MAX=128
  Bin 4: [30, 33) tokens, B_MAX=128
  Bin 5: [33, 37) tokens, B_MAX=128
  Bin 6: [37, 40) tokens, B_MAX=128
  Bin 7: [40, 42) tokens, B_MAX=128
  Bin 8: [42, 45) tokens, B_MAX=128
  Bin 9: [45, 48) tokens, B_MAX=128
  Bin 10: [48, 51) tokens, B_MAX=128
  Bin 11: [51, 56) tokens, B_MAX=128
  Bin 12: [56, 61) tokens, B_MAX=128
  Bin 13: [61, 67) tokens, B_MAX=128
  Bin 14: [67, 73) tokens, B_MAX=128
  Bin 15: [73, 80) tokens, B_MAX=128
  Bin 16: [80, 89) tokens, B_MAX=128
  Bin 17: [89, 98) tokens, B_MAX=128
  Bin 18: [98, 107) tokens, B_MAX=128
  Bin 19: [107, 117) tokens, B_MAX=128
  Bin 20: [117, 130) tokens, B_MAX=128
  Bin 21: [130, 143) tokens, B_MAX=128
  Bin 22: [143, 155) tokens, B_MAX=125
  Bin 23: [155, 167) tokens, B_MAX=115
  Bin 24: [167, 181) tokens, B_MAX=107
  Bin 25: [181, 200) tokens, B_MAX=98
  Bin 26: [200, 232) tokens, B_MAX=86
  Bin 27: [232, 281) tokens, B_MAX=72
  Bin 28: [281, 324) tokens, B_MAX=61
  Bin 29: [324, 363) tokens, B_MAX=54
  Bin 30: [363, 412) tokens, B_MAX=48
  Bin 31: [412, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
======================================================================
BATCH 1M CONFIGURATION RUNNER
======================================================================

Missing configurations: 39
Estimated time: 58 - 78 minutes


[1/39] Running: GPUs=2, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[2/39] Running: GPUs=2, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[3/39] Running: GPUs=2, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[4/39] Running: GPUs=4, K=1
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[5/39] Running: GPUs=4, K=2
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[6/39] Running: GPUs=4, K=4
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[7/39] Running: GPUs=4, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[8/39] Running: GPUs=4, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[9/39] Running: GPUs=4, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[10/39] Running: GPUs=8, K=1
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[11/39] Running: GPUs=8, K=2
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[12/39] Running: GPUs=8, K=4
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[13/39] Running: GPUs=8, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[14/39] Running: GPUs=8, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[15/39] Running: GPUs=8, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[16/39] Running: GPUs=16, K=1
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[17/39] Running: GPUs=16, K=2
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[18/39] Running: GPUs=16, K=4
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[19/39] Running: GPUs=16, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[20/39] Running: GPUs=16, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[21/39] Running: GPUs=16, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[22/39] Running: GPUs=32, K=1
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[23/39] Running: GPUs=32, K=2
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[24/39] Running: GPUs=32, K=4
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[25/39] Running: GPUs=32, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[26/39] Running: GPUs=32, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[27/39] Running: GPUs=32, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[28/39] Running: GPUs=64, K=1
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[29/39] Running: GPUs=64, K=2
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[30/39] Running: GPUs=64, K=4
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[31/39] Running: GPUs=64, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[32/39] Running: GPUs=64, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[33/39] Running: GPUs=64, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[34/39] Running: GPUs=100, K=1
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[35/39] Running: GPUs=100, K=2
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[36/39] Running: GPUs=100, K=4
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[37/39] Running: GPUs=100, K=8
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[38/39] Running: GPUs=100, K=16
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

[39/39] Running: GPUs=100, K=32
--------------------------------------------------
[FAILED] unsupported operand type(s) for *: 'dict' and 'int'
Traceback (most recent call last):
  File "C:\Us

======================================================================
COMPLETED: 0/39
FAILED: 39
======================================================================
