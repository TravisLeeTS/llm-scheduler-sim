======================================================================
STRESS TEST v4: TTFT/TBT SEPARATION MODEL
======================================================================

v4 Changes:
- Token SLA applies ONLY to decode TBT (beta ~ 5.74ms/token)
- TTFT (alpha ~ 60ms) is tracked separately, not in token SLA
- Eliminates structural violations where TTFT dominates

======================================================================
STEP 1: GRID SEARCH (multi_bin_dynamic)
======================================================================
Token SLA: 10.0ms (decode TBT only, excludes TTFT)
Request SLA: 20.0s
RPS Scaling: 200.0x

Loaded 101 existing results

[102/192] 100,000 req, GPUs=1, K=32
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 100000 requests from dataset
SLA thresholds: Per-token=10.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Using real GPU calibration from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv

LatencyModel fitted from C:\Users\tings\llm_scheduler_sim\scripts\..\data\qwen3_1_7b_latency_grid.csv:
  alpha (base latency):    59.653 ms
  beta (per-token coeff):  5.74200 ms/token
  gamma (batch penalty):   0.316
  R^2 fit quality:         0.9995
LatencyModel info: {'calibrated': True, 'method': 'real_gpu_fitted', 'alpha': np.float64(0.05965277786696989), 'beta': np.float64(0.005741996981393911), 'gamma': np.float64(0.31568071151206994)}
[Bins] Computed equal-mass boundaries from 100000 requests:
  Bin 0: [1, 11) tokens, B_MAX=128
  Bin 1: [11, 20) tokens, B_MAX=128
  Bin 2: [20, 23) tokens, B_MAX=128
  Bin 3: [23, 24) tokens, B_MAX=128
  Bin 4: [24, 25) tokens, B_MAX=128
  Bin 5: [25, 25) tokens, B_MAX=128
  Bin 6: [25, 26) tokens, B_MAX=128
  Bin 7: [26, 26) tokens, B_MAX=128
  Bin 8: [26, 27) tokens, B_MAX=128
  Bin 9: [27, 27) tokens, B_MAX=128
  Bin 10: [27, 28) tokens, B_MAX=128
  Bin 11: [28, 28) tokens, B_MAX=128
  Bin 12: [28, 28) tokens, B_MAX=128
  Bin 13: [28, 29) tokens, B_MAX=128
  Bin 14: [29, 30) tokens, B_MAX=128
  Bin 15: [30, 30) tokens, B_MAX=128
  Bin 16: [30, 31) tokens, B_MAX=128
  Bin 17: [31, 32) tokens, B_MAX=128
  Bin 18: [32, 33) tokens, B_MAX=128
  Bin 19: [33, 35) tokens, B_MAX=128
  Bin 20: [35, 38) tokens, B_MAX=128
  Bin 21: [38, 57) tokens, B_MAX=128
  Bin 22: [57, 91) tokens, B_MAX=128
  Bin 23: [91, 119) tokens, B_MAX=128
  Bin 24: [119, 155) tokens, B_MAX=128
  Bin 25: [155, 194) tokens, B_MAX=107
  Bin 26: [194, 229) tokens, B_MAX=88
  Bin 27: [229, 264) tokens, B_MAX=75
  Bin 28: [264, 320) tokens, B_MAX=63
  Bin 29: [320, 381) tokens, B_MAX=53
  Bin 30: [381, 420) tokens, B_MAX=46
  Bin 31: [420, 10000) tokens, B_MAX=8
[Scheduler Init] multi_bin_dynamic: K_BINS=32 + DynamicBatcher (SLA controller)
    Token SLA: 0.0% | Request SLA: 99.9% | Decode TBT: 7.05ms | Batch: 3.6 | Time: 10.4s
Saved 102 results to C:\Users\tings\llm_scheduler_sim\scripts\..\stress_test_v4_results\step1_grid_search.csv

[103/192] 100,000 req, GPUs=2, K=1
Loading BurstGPT dataset from: C:\Users\tings\llm_scheduler_sim\scripts\..\data\BurstGPT_sample.csv
Loaded 100000 requests from dataset
SLA thresholds: Per-token=10.0ms, Per-request=20000.0ms
Applying RPS scaling factor: 200.00x
Traceback (most recent call last):
  File "C:\Users\tings\llm_scheduler_sim\scripts\stress_test_v4.py", line 370, in <module>
    main()
  File "C:\Users\tings\llm_scheduler_sim\scripts\stress_test_v4.py", line 350, in main
    step1_results = run_step1_grid_search()
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tings\llm_scheduler_sim\scripts\stress_test_v4.py", line 187, in run_step1_grid_search
    result = run_single_experiment(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tings\llm_scheduler_sim\scripts\stress_test_v4.py", line 81, in run_single_experiment
    requests = generate_workload(cfg)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tings\llm_scheduler_sim\mb_dyn_sim\workload.py", line 252, in generate_workload
    return load_burstgpt_dataset(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tings\llm_scheduler_sim\mb_dyn_sim\workload.py", line 190, in load_burstgpt_dataset
    prompt_len = int(row[prompt_col])
                     ~~~^^^^^^^^^^^^
  File "C:\Users\tings\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\series.py", line 1121, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tings\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tings\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
^C